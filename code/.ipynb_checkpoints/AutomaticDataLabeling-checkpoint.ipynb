{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Data Labeling for Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading Data\n",
    "2. **Writing Labeling Functions**: We write Python programs that take as input a data point and assign labels (or abstain) using heuristics, pattern matching, and third-party models.\n",
    "\n",
    "3. **Combining Labeling Function Outputs with the Label Model**: We model the outputs of the labeling functions over the training set using a novel, theoretically-grounded [modeling approach](https://arxiv.org/abs/1605.07723), which estimates the accuracies and correlations of the labeling functions using only their agreements and disagreements, and then uses this to reweight and combine their outputs, which we then use as _probabilistic_ training labels.\n",
    "\n",
    "4. **Training a Classifier**: We train a classifier that can predict labels for *any* YouTube comment (not just the ones labeled by the labeling functions) using the probabilistic training labels from step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads train/test files\n",
    "def read_data(filepath):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for line in open(filepath):\n",
    "        sentence, label = line.strip().split(\"\\t\")\n",
    "        labels.append(label)\n",
    "        texts.append(sentence)\n",
    "    return texts, labels\n",
    "    \n",
    "train_texts, discard = read_data(\"../files/train_labelled.txt\")\n",
    "test_texts, test_labels = read_data(\"../files/test_labelled.txt\")\n",
    "discard = None #training labels are discarded. We won't use them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing Labeling Functions (LFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Exploring the training set for initial ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by looking at 20 random data points from the `train` set to generate some ideas for LFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"***SPOILERS*** Whatever else can (or can't) be said about it, SURFACE is superbly crafted.  \",\n",
       " \"The shower area is outside so you can only rinse, not take a full shower, unless you don't mind being nude for everyone to see!\",\n",
       " \"I started this review with two stars, but I'm editing it to give it only one.\",\n",
       " 'The meat was pretty dry, I had the sliced brisket and pulled pork.',\n",
       " 'We loved the biscuits!!!',\n",
       " \"I mean really, how do you get so famous for your fish and chips when it's so terrible!?!\",\n",
       " 'Although I very much liked the look and sound of this place, the actual experience was a bit disappointing.',\n",
       " 'STEAMBOAT WILLIE is an amazingly important film to our cinema history.  ',\n",
       " 'The food was very good.',\n",
       " 'It has a very good plot, it holds your complete attention, the acting is superb, Tom Wilkinson was fantastic and Emily Watson was also very good.  ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(train_texts,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"We won't be returning.\",\n",
       " 'He was extremely rude and really, there are so many other restaurants I would love to dine at during a weekend in Vegas.',\n",
       " 'It is PERFECT for a sit-down family meal or get together with a few friends.',\n",
       " 'The service was meh.',\n",
       " 'this was a different cut than the piece the other day but still wonderful and tender s well as well flavored.',\n",
       " 'What this film lacks is a convincing script.  ',\n",
       " 'This place is amazing!',\n",
       " 'If you see it, you should probably just leave it on the shelf.  ',\n",
       " 'This is my new fav Vegas buffet spot.',\n",
       " 'Whatever the producer was going for, he missed entirely.  ']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(train_texts,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = DataFrame (train_texts,columns=['text'])\n",
    "df_test = DataFrame(test_texts,columns=['text'])\n",
    "df_test['label'] = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One dominant pattern in the comments that look like spam (which we might know from prior domain experience, or from inspection of a few training data points) is the use of the phrase \"check out\" (e.g. \"check out my channel\").\n",
    "Let's start with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Writing a few LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling functions in Snorkel are created with the\n",
    "[`@labeling_function` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.labeling_function.html).\n",
    "The [decorator](https://realpython.com/primer-on-python-decorators/) can be applied to _any Python function_ that returns a label for a single data point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load positive and negative words lists.\n",
    "def getlist(filepath):\n",
    "    mylist = []\n",
    "    for line in open(filepath, encoding=\"utf-8\"):\n",
    "        if line and not line.startswith(\";\"):\n",
    "            mylist.append(line.strip())\n",
    "    return mylist\n",
    "\n",
    "positives = getlist(\"../files/positive-words.txt\")\n",
    "negatives = getlist(\"../files/negative-words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "4783\n"
     ]
    }
   ],
   "source": [
    "print(len(positives))\n",
    "print(len(negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "import re\n",
    "\n",
    "POS=1\n",
    "NEG=0\n",
    "ABSTAIN=-1\n",
    "\n",
    "@labeling_function()\n",
    "def postive(x):\n",
    "    poswords = 0\n",
    "    temp = x.text.split()\n",
    "    for word in temp:\n",
    "        if word in positives:\n",
    "            poswords +=1\n",
    "    if poswords > 0:\n",
    "        return POS\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "@labeling_function()\n",
    "def negative(x):\n",
    "    negwords = 0\n",
    "    temp = x.text.split()\n",
    "    for word in temp:\n",
    "        if word in negatives:\n",
    "            negwords +=1\n",
    "    if negwords > 0:\n",
    "        return NEG\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def decision(x):\n",
    "    if x.text.isupper():\n",
    "        return NEG\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply one or more LFs that we've written to a collection of data points, we use an\n",
    "[`LFApplier`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LFApplier.html).\n",
    "Because our data points are represented with a Pandas DataFrame in this tutorial, we use the\n",
    "[`PandasLFApplier`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.PandasLFApplier.html).\n",
    "Correspondingly, a single data point `x` that's passed into our LFs will be a [Pandas `Series` object](https://pandas.pydata.org/pandas-docs/stable/reference/series.html).\n",
    "\n",
    "It's important to note that these LFs will work for any object with an attribute named `text`, not just Pandas objects.\n",
    "Snorkel has several other appliers for different data point collection types which you can browse in the [API documentation](https://snorkel.readthedocs.io/en/master/packages/labeling.html).\n",
    "\n",
    "The output of the `apply(...)` method is a ***label matrix***, a fundamental concept in Snorkel.\n",
    "It's a NumPy array `L` with one column for each LF and one row for each data point, where `L[i, j]` is the label that the `j`th labeling function output for the `i`th data point.\n",
    "We'll create a label matrix for the `train` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1187.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "from pandas import DataFrame\n",
    "\n",
    "lfs = [postive,negative,decision]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Evaluate performance on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of statistics about labeling functions &mdash; like coverage &mdash; are useful when building any Snorkel application.\n",
    "So Snorkel provides tooling for common LF analyses using the\n",
    "[`LFAnalysis` utility](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html).\n",
    "We report the following summary statistics for multiple LFs at once:\n",
    "\n",
    "* **Polarity**: The set of unique labels this LF outputs (excluding abstains)\n",
    "* **Coverage**: The fraction of the dataset the LF labels\n",
    "* **Overlaps**: The fraction of the dataset where this LF and at least one other LF label\n",
    "* **Conflicts**: The fraction of the dataset where this LF and at least one other LF label and disagree\n",
    "* **Correct**: The number of data points this LF labels correctly (if gold labels are provided)\n",
    "* **Incorrect**: The number of data points this LF labels incorrectly (if gold labels are provided)\n",
    "* **Empirical Accuracy**: The empirical accuracy of this LF (if gold labels are provided)\n",
    "\n",
    "For *Correct*, *Incorrect*, and *Empirical Accuracy*, we don't want to penalize the LF for data points where it abstained.\n",
    "We calculate these statistics only over those data points where the LF output a label.\n",
    "**Note that in our current setup, we can't compute these statistics because we don't have any ground-truth labels (other than in the test set, which we cannot look at). Not to worry—Snorkel's `LabelModel` will estimate them without needing any ground-truth labels in the next step!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>postive</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.4360</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          j Polarity  Coverage  Overlaps  Conflicts\n",
       "postive   0      [1]    0.4360    0.0915     0.0915\n",
       "negative  1      [0]    0.2520    0.0915     0.0915\n",
       "decision  2      [0]    0.0035    0.0000     0.0000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "lfs = [postive,negative, decision]\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combining Labeling Function Outputs with the Label Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates just a handful of the types of LFs that one might write for this task.\n",
    "One of the key goals of Snorkel is _not_ to replace the effort, creativity, and subject matter expertise required to come up with these labeling functions, but rather to make it faster to write them, since **in Snorkel the labeling functions are assumed to be noisy, i.e. innaccurate, overlapping, etc.**\n",
    "Said another way: the LF abstraction provides a flexible interface for conveying a huge variety of supervision signals, and the `LabelModel` is able to denoise these signals, reducing the need for painstaking manual fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we perform some LFs analysis and finalize our list,  we can now apply these once again with `LFApplier` to get the label matrices.\n",
    "The Pandas format provides an easy interface that many practitioners are familiar with, but it is also less optimized for scale.\n",
    "For larger datasets, more compute-intensive LFs, or larger LF sets, you may decide to use one of the other data formats\n",
    "that Snorkel supports natively, such as Dask DataFrames or PySpark DataFrames, and their corresponding applier objects.\n",
    "For more info, check out the [Snorkel API documentation](https://snorkel.readthedocs.io/en/master/packages/labeling.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1177.12it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1468.39it/s]\n"
     ]
    }
   ],
   "source": [
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_test = applier.apply(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>postive</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.4360</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          j Polarity  Coverage  Overlaps  Conflicts\n",
       "postive   0      [1]    0.4360    0.0915     0.0915\n",
       "negative  1      [0]    0.2520    0.0915     0.0915\n",
       "decision  2      [0]    0.0035    0.0000     0.0000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "We see that our labeling functions vary in coverage, how much they overlap/conflict with one another, and almost certainly their accuracies as well.\n",
    "We can view a histogram of how many LF labels the data points in our train set have to get an idea of our total coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_label_frequency(L):\n",
    "    plt.hist((L != ABSTAIN).sum(axis=1), density=True, bins=range(L.shape[1]))\n",
    "    plt.xlabel(\"Number of labels\")\n",
    "    plt.ylabel(\"Fraction of dataset\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_label_frequency(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "We see that over half of our `train` dataset data points have 2 or fewer labels from LFs.\n",
    "Fortunately, the labels we do have can be used to train a classifier over the comment text directly, allowing this final machine learning model to generalize beyond what our labeling functions labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is now to convert the labels from our LFs into a single _noise-aware_ probabilistic (or confidence-weighted) label per data point.\n",
    "A simple baseline for doing this is to take the majority vote on a per-data point basis: if more LFs voted SPAM than HAM, label it SPAM (and vice versa).\n",
    "We can test this with the\n",
    "[`MajorityLabelVoter` baseline model](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.model.baselines.MajorityLabelVoter.html#snorkel.labeling.model.baselines.MajorityLabelVoter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as we can see from the summary statistics of our LFs in the previous section, they have varying properties and should not be treated identically. In addition to having varied accuracies and coverages, LFs may be correlated, resulting in certain signals being overrepresented in a majority-vote-based model. To handle these issues appropriately, we will instead use a more sophisticated Snorkel `LabelModel` to combine the outputs of the LFs.\n",
    "\n",
    "This model will ultimately produce a single set of noise-aware training labels, which are probabilistic or confidence-weighted labels. We will then use these labels to train a classifier for our task. For more technical details of this overall approach, see our [NeurIPS 2016](https://arxiv.org/abs/1605.07723) and [AAAI 2019](https://arxiv.org/abs/1810.02840) papers. For more info on the API, see the [`LabelModel` documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.model.label_model.LabelModel.html#snorkel.labeling.model.label_model.LabelModel).\n",
    "\n",
    "Note that no gold labels are used during the training process.\n",
    "The only information we need is the label matrix, which contains the output of the LFs on our training set.\n",
    "The `LabelModel` is able to learn weights for the labeling functions using only the label matrix as input.\n",
    "We also specify the `cardinality`, or number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nY_test = df_test.label.values\\n\\nmajority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\"accuracy\"]\\nprint(f\"{\\'Majority Vote Accuracy:\\':<25} {majority_acc * 100:.1f}%\")\\n\\nlabel_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\"accuracy\"]\\nprint(f\"{\\'Label Model Accuracy:\\':<25} {label_model_acc * 100:.1f}%\")\\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L=L_train)\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)\n",
    "\n",
    "\"\"\"\n",
    "Y_test = df_test.label.values\n",
    "\n",
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority vote model or more sophisticated `LabelModel` could in principle be used directly as a classifier if the outputs of our labeling functions were made available at test time.\n",
    "However, these models (i.e. these re-weighted combinations of our labeling function's votes) will abstain on the data points that our labeling functions don't cover (and additionally, may require slow or unavailable features to execute at test time).\n",
    "In the next section, we will instead use the outputs of the `LabelModel` as training labels to train a discriminative classifier **which can generalize beyond the labeling function outputs** to see if we can improve performance further.\n",
    "This classifier will also only need the text of the comment to make predictions, making it much more suitable for inference over unseen comments.\n",
    "For more information on the properties of the label model, see the [Snorkel documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.model.label_model.LabelModel.html#snorkel.labeling.model.label_model.LabelModel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "Let's briefly confirm that the labels the `LabelModel` produces are indeed probabilistic in nature.\n",
    "The following histogram shows the confidences we have that each data point has the label SPAM.\n",
    "The points we are least certain about will have labels close to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def plot_probabilities_histogram(Y):\n",
    "    plt.hist(Y, bins=10)\n",
    "    plt.xlabel(\"Probability of SPAM\")\n",
    "    plt.ylabel(\"Number of data points\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "probs_train = label_model.predict_proba(L=L_train)\n",
    "plot_probabilities_histogram(probs_train[:, POS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out unlabeled data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier, some of the data points in our `train` set received no labels from any of our LFs.\n",
    "These data points convey no supervision signal and tend to hurt performance, so we filter them out before training using a\n",
    "[built-in utility](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.filter_unlabeled_dataframe.html#snorkel.labeling.filter_unlabeled_dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1)\n",
      "(1200, 1)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_train_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final section of the tutorial, we'll use the probabilistic training labels we generated in the last section to train a classifier for our task.\n",
    "**The output of the Snorkel `LabelModel` is just a set of labels which can be used with most popular libraries for performing supervised learning, such as TensorFlow, Keras, PyTorch, Scikit-Learn, Ludwig, and XGBoost.**\n",
    "In this tutorial, we use the well-known library [Scikit-Learn](https://scikit-learn.org).\n",
    "**Note that typically, Snorkel is used (and really shines!) with much more complex, training data-hungry models, but we will use Logistic Regression here for simplicity of exposition.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity and speed, we use a simple \"bag of n-grams\" feature representation: each data point is represented by a one-hot vector marking which words or 2-word combinations are present in the comment text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 55023)\n",
      "(1000, 55023)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.text.tolist())\n",
    "X_test = vectorizer.transform(df_test.text.tolist())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in Section 4, the `LabelModel` outputs probabilistic (float) labels.\n",
    "If the classifier we are training accepts target labels as floats, we can train on these labels directly (see describe the properties of this type of \"noise-aware\" loss in our [NeurIPS 2016 paper](https://arxiv.org/abs/1605.07723)).\n",
    "\n",
    "If we want to use a library or model that doesn't accept probabilistic labels (such as Scikit-Learn), we can instead replace each label distribution with the label of the class that has the maximum probability.\n",
    "This can easily be done using the\n",
    "[`probs_to_preds` helper method](https://snorkel.readthedocs.io/en/master/packages/_autosummary/utils/snorkel.utils.probs_to_preds.html#snorkel.utils.probs_to_preds).\n",
    "We do note, however, that this transformation is lossy, as we no longer have values for our confidence in each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use these labels to train a classifier as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for  LogisticRegression\n",
      "Test Accuracy: 0.0%\n",
      "[0 0 1 ... 1 1 1]\n",
      "Performance for  LinearSVC\n",
      "Test Accuracy: 0.0%\n",
      "[0 0 1 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:182: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "Y_test = df_test.label.values\n",
    "\n",
    "for classifier in [LogisticRegression(C=1e3, solver=\"liblinear\"), LinearSVC()]:\n",
    "    classifier.fit(X=X_train, y=preds_train_filtered)\n",
    "    print(\"Performance for \", type(classifier).__name__), \n",
    "    print(f\"Test Accuracy: {classifier.score(X=X_test, y=test_labels) * 100:.1f}%\")\n",
    "    print(preds_train_filtered)\n",
    "    print(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We observe an additional boost in accuracy over the `LabelModel` by multiple points! This is in part because the discriminative model generalizes beyond the labeling function's labels and makes good predictions on all data points, not just the ones covered by labeling functions.\n",
    "By using the label model to transfer the domain knowledge encoded in our LFs to the discriminative model,\n",
    "we were able to generalize beyond the noisy labeling heuristics**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we accomplished the following:\n",
    "* We introduced the concept of Labeling Functions (LFs) and demonstrated some of the forms they can take.\n",
    "* We used the Snorkel `LabelModel` to automatically learn how to combine the outputs of our LFs into strong probabilistic labels.\n",
    "* We showed that a classifier trained on a weakly supervised dataset can outperform an approach based on the LFs alone as it learns to generalize beyond the noisy heuristics we provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation: Writing Transformation Functions (TFs)\n",
    "\n",
    "Transformation functions are functions that can be applied to a training data point to create another valid training data point of the same class.\n",
    "For example, for image classification problems, it is common to rotate or crop images in the training data to create new training inputs.\n",
    "Transformation functions should be atomic e.g. a small rotation of an image, or changing a single word in a sentence.\n",
    "We then compose multiple transformation functions when applying them to training data points.\n",
    "\n",
    "Common ways to augment text includes replacing words with their synonyms, or replacing names entities with other entities.\n",
    "More info can be found\n",
    "[here](https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28) or\n",
    "[here](https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610).\n",
    "Our basic modeling assumption is that applying these operations to a comment generally shouldn't change whether it is `SPAM` or not.\n",
    "\n",
    "Transformation functions in Snorkel are created with the\n",
    "[`transformation_function` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/augmentation/snorkel.augmentation.transformation_function.html#snorkel.augmentation.transformation_function),\n",
    "which wraps a function that takes in a single data point and returns a transformed version of the data point.\n",
    "If no transformation is possible, a TF can return `None` or the original data point.\n",
    "If all the TFs applied to a data point return `None`, the data point won't be included in\n",
    "the augmented dataset when we apply our TFs below.\n",
    "\n",
    "Just like the `labeling_function` decorator, the `transformation_function` decorator\n",
    "accepts `pre` argument for `Preprocessor` objects.\n",
    "Here, we'll use a\n",
    "[`SpacyPreprocessor`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.nlp.SpacyPreprocessor.html#snorkel.preprocess.nlp.SpacyPreprocessor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us reload the dataset, with labels now. \n",
    "df_train, df_test = load_spam_dataset(load_train_labels=True)\n",
    "# We pull out the label vectors for ease of use later\n",
    "Y_train = df_train[\"label\"].values\n",
    "Y_test = df_test[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "\n",
    "spacy = SpacyPreprocessor(text_field=\"text\", doc_field=\"doc\", memoize=True)\n",
    "\n",
    "import names\n",
    "from snorkel.augmentation import transformation_function\n",
    "\n",
    "# Pregenerate some random person names to replace existing ones with\n",
    "# for the transformation strategies below\n",
    "replacement_names = [names.get_full_name() for _ in range(50)]\n",
    "\n",
    "\n",
    "# Replace a random named entity with a different entity of the same type.\n",
    "@transformation_function(pre=[spacy])\n",
    "def change_person(x):\n",
    "    person_names = [ent.text for ent in x.doc.ents if ent.label_ == \"PERSON\"]\n",
    "    # If there is at least one person name, replace a random one. Else return None.\n",
    "    if person_names:\n",
    "        name_to_replace = np.random.choice(person_names)\n",
    "        replacement_name = np.random.choice(replacement_names)\n",
    "        x.text = x.text.replace(name_to_replace, replacement_name)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Swap two adjectives at random.\n",
    "@transformation_function(pre=[spacy])\n",
    "def swap_adjectives(x):\n",
    "    adjective_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"ADJ\"]\n",
    "    # Check that there are at least two adjectives to swap.\n",
    "    if len(adjective_idxs) >= 2:\n",
    "        idx1, idx2 = sorted(np.random.choice(adjective_idxs, 2, replace=False))\n",
    "        # Swap tokens in positions idx1 and idx2.\n",
    "        x.text = \" \".join(\n",
    "            [\n",
    "                x.doc[:idx1].text,\n",
    "                x.doc[idx2].text,\n",
    "                x.doc[1 + idx1 : idx2].text,\n",
    "                x.doc[idx1].text,\n",
    "                x.doc[1 + idx2 :].text,\n",
    "            ]\n",
    "        )\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add other wordnet based transformation funtions from NLTK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "\n",
    "def get_synonym(word, pos=None):\n",
    "    \"\"\"Get synonym for word given its part-of-speech (pos).\"\"\"\n",
    "    synsets = wn.synsets(word, pos=pos)\n",
    "    # Return None if wordnet has no synsets (synonym sets) for this word and pos.\n",
    "    if synsets:\n",
    "        words = [lemma.name() for lemma in synsets[0].lemmas()]\n",
    "        if words[0].lower() != word.lower():  # Skip if synonym is same as word.\n",
    "            # Multi word synonyms in wordnet use '_' as a separator e.g. reckon_with. Replace it with space.\n",
    "            return words[0].replace(\"_\", \" \")\n",
    "\n",
    "\n",
    "def replace_token(spacy_doc, idx, replacement):\n",
    "    \"\"\"Replace token in position idx with replacement.\"\"\"\n",
    "    return \" \".join([spacy_doc[:idx].text, replacement, spacy_doc[1 + idx :].text])\n",
    "\n",
    "\n",
    "@transformation_function(pre=[spacy])\n",
    "def replace_verb_with_synonym(x):\n",
    "    # Get indices of verb tokens in sentence.\n",
    "    verb_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"VERB\"]\n",
    "    if verb_idxs:\n",
    "        # Pick random verb idx to replace.\n",
    "        idx = np.random.choice(verb_idxs)\n",
    "        synonym = get_synonym(x.doc[idx].text, pos=\"v\")\n",
    "        # If there's a valid verb synonym, replace it. Otherwise, return None.\n",
    "        if synonym:\n",
    "            x.text = replace_token(x.doc, idx, synonym)\n",
    "            return x\n",
    "\n",
    "\n",
    "@transformation_function(pre=[spacy])\n",
    "def replace_noun_with_synonym(x):\n",
    "    # Get indices of noun tokens in sentence.\n",
    "    noun_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"NOUN\"]\n",
    "    if noun_idxs:\n",
    "        # Pick random noun idx to replace.\n",
    "        idx = np.random.choice(noun_idxs)\n",
    "        synonym = get_synonym(x.doc[idx].text, pos=\"n\")\n",
    "        # If there's a valid noun synonym, replace it. Otherwise, return None.\n",
    "        if synonym:\n",
    "            x.text = replace_token(x.doc, idx, synonym)\n",
    "            return x\n",
    "\n",
    "\n",
    "@transformation_function(pre=[spacy])\n",
    "def replace_adjective_with_synonym(x):\n",
    "    # Get indices of adjective tokens in sentence.\n",
    "    adjective_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"ADJ\"]\n",
    "    if adjective_idxs:\n",
    "        # Pick random adjective idx to replace.\n",
    "        idx = np.random.choice(adjective_idxs)\n",
    "        synonym = get_synonym(x.doc[idx].text, pos=\"a\")\n",
    "        # If there's a valid adjective synonym, replace it. Otherwise, return None.\n",
    "        if synonym:\n",
    "            x.text = replace_token(x.doc, idx, synonym)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = [\n",
    "    change_person,\n",
    "    swap_adjectives,\n",
    "    replace_verb_with_synonym,\n",
    "    replace_noun_with_synonym,\n",
    "    replace_adjective_with_synonym,\n",
    "]\n",
    "from utils import preview_tfs\n",
    "import numpy as np\n",
    "\n",
    "preview_tfs(df_train, tfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice a couple of things about the TFs.\n",
    "\n",
    "    Sometimes they make trivial changes (\"website\" to \"web site\" for replace_noun_with_synonym). This can still be helpful for training our model, because it teaches the model to be invariant to such small changes.\n",
    "    Sometimes they introduce incorrect grammar to the sentence (e.g. swap_adjectives swapping \"young\" and \"more\" above).\n",
    "\n",
    "The TFs are expected to be heuristic strategies that indeed preserve the class most of the time, but don't need to be perfect. This is especially true when using automated data augmentation techniques which can learn to avoid particularly corrupted data points. As we'll see below, Snorkel is compatible with such learned augmentation policies.\n",
    "\n",
    "3. Applying Transformation Functions\n",
    "\n",
    "We'll first define a Policy to determine what sequence of TFs to apply to each data point. We'll start with a RandomPolicy that samples sequence_length=2 TFs to apply uniformly at random per data point. The n_per_original argument determines how many augmented data points to generate per original data point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.augmentation import RandomPolicy\n",
    "\n",
    "random_policy = RandomPolicy(\n",
    "    len(tfs), sequence_length=2, n_per_original=2, keep_original=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, we can do better than uniform random sampling. We might have domain knowledge that some TFs should be applied more frequently than others, or have trained an automated data augmentation model that learned a sampling distribution for the TFs. Snorkel supports this use case with a MeanFieldPolicy, which allows you to specify a sampling distribution for the TFs. We give higher probabilities to the replace_[X]_with_synonym TFs, since those provide more information to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.augmentation import MeanFieldPolicy\n",
    "\n",
    "mean_field_policy = MeanFieldPolicy(\n",
    "    len(tfs),\n",
    "    sequence_length=2,\n",
    "    n_per_original=2,\n",
    "    keep_original=True,\n",
    "    p=[0.05, 0.05, 0.3, 0.3, 0.3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To apply one or more TFs that we've written to a collection of data points according to our policy, \n",
    "#we use a PandasTFApplier because our data points are represented with a Pandas DataFrame.\n",
    "\n",
    "from snorkel.augmentation import PandasTFApplier\n",
    "\n",
    "tf_applier = PandasTFApplier(tfs, mean_field_policy)\n",
    "\n",
    "df_train_augmented = tf_applier.apply(df_train)\n",
    "\n",
    "Y_train_augmented = df_train_augmented[\"label\"].values\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_train_augmented.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have almost doubled our dataset using TFs! Note that despite n_per_original being set to 2, our dataset may not exactly triple in size, because sometimes TFs return None instead of a new data point (e.g. change_person when applied to a sentence with no persons). If you prefer to have exact proportions for your dataset, you can have TFs that can't perform a valid transformation return the original data point rather than None (as they do here).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Training A Model\n",
    "\n",
    "Our final step is to use the augmented data to train a model. We can use the same classifier setup as before:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X_train_augmented = vectorizer.fit_transform(df_train_augmented.text.tolist())\n",
    "\n",
    "X_test = vectorizer.transform(df_test.text.tolist())\n",
    "\n",
    "print(X_train_augmented.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train_augmented.shape)\n",
    "print(set(Y_train_augmented))\n",
    "\n",
    "for classifier in [LogisticRegression(C=1e3, solver=\"liblinear\"), LinearSVC()]:\n",
    "    classifier.fit(X=X_train_augmented, y=Y_train_augmented)\n",
    "    print(\"Performance for \", type(classifier).__name__), \n",
    "    print(f\"Test Accuracy: {classifier.score(X=X_test, y=Y_test) * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of the dataset, with known labels, with some basic feature engineering\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X_train = vectorizer.fit_transform(df_train.text.tolist())\n",
    "X_test = vectorizer.transform(df_test.text.tolist())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "for classifier in [LogisticRegression(C=1e3, solver=\"liblinear\"), LinearSVC()]:\n",
    "    classifier.fit(X=X_train, y=Y_train)\n",
    "    print(\"Performance for \", type(classifier).__name__), \n",
    "    print(f\"Test Accuracy: {classifier.score(X=X_test, y=Y_test) * 100:.1f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, was this a useful exercise?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
